{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9043d05b-96ae-460e-987e-385d5d7370ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "# Classify the sentence/comment/review/feedback into positive or negative\n",
    "\n",
    "# Text Processing - NLP - Natural Language Processing\n",
    "\"\"\"\n",
    "1. Tokenization\n",
    "2. Remove stopwords and punctuations\n",
    "3. Lemmatization\n",
    "4. Vectorization\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Example - The product is very bad and it's a waste of money\n",
    "Step - 1 : tokenization + lowercase\n",
    "= [\"the\", \"product\", \"is\", \"very\", \"bad\", \"and\", \"it's\", \"a\", \"waste\", \"of\", \"money\"]\n",
    "\n",
    "Step - 2 : remove stopwords (and, is, are, the, that, a, if, but) and punctuations (!,@,#,$,%,^,&,*)\n",
    "= [\"product\", \"very\", \"bad\", \"waste\", \"money\"]\n",
    "\n",
    "Step - 3 : lemmatization - play - playing, played... waste - wasting, wasted\n",
    "= []\n",
    "\n",
    "Step - 4 : Vectorization - Count Vectorization, TF-IDF, Hashing\n",
    "TF - Term Frequency\n",
    "IDF - Inverse Document Frequency\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, StringIndexer, HashingTF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515105f8-693f-4502-ae96-0cb46b337b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/25 14:22:19 WARN Utils: Your hostname, Ravikants-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.10.47 instead (on interface en0)\n",
      "24/10/25 14:22:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/25 14:22:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/10/25 14:22:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"sentiment_analysis_app_2\").config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").config(\"spark.executor.cores\", \"4\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114dc9c4-ab81-4b7d-a74f-c68733940f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"IMDB Dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e337326c-3237-4611-92a9-e711e7cede39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.10.47:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sentiment_analysis_app_2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10fd6f500>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3533ed8f-351b-4ecd-bd91-190dd07dc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ecf0b1-d3d2-40a5-8e62-57ce2ca45510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              review|           sentiment|\n",
      "+--------------------+--------------------+\n",
      "|One of the other ...|            positive|\n",
      "|\"A wonderful litt...| not only is it w...|\n",
      "|\"I thought this w...| but spirited you...|\n",
      "|Basically there's...|            negative|\n",
      "|\"Petter Mattei's ...| power and succes...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba584a8-2137-4dcb-ba9d-fdfe9cca2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acfec3f9-c061-42b7-b168-18088a9f3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional step - renaming columns\n",
    "df = df.withColumnRenamed(\"sentiment\", \"label\").withColumnRenamed(\"review\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bf3c905-1244-444c-9ddf-b3ee9365289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|\".... may seem fa...| NULL|\n",
      "|\"And that comes f...| NULL|\n",
      "|\"Sorry everyone,,...| NULL|\n",
      "|\"With a special t...| NULL|\n",
      "|\"I've seen a lot ...| NULL|\n",
      "|\"I happened to se...| NULL|\n",
      "|\"seriously what t...| NULL|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"label\"].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a96487c-3f73-4c96-9e7f-0bf54eb8ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df[\"label\"].isNotNull()).withColumn(\"label\", df[\"label\"].cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc2c8d07-8d6b-44a4-90f2-4870b7b89208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(fraction=0.5)\n",
    "df = df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c53335c9-6c25-478e-97ae-e2c5f0b0fb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15931"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67b2e2b8-bf27-4cf9-a0a2-3cdf8b0d6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sentiment labels (positive and negative) to numeric format\n",
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b83c8f88-c29a-439a-8bbf-a7c66ac9c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7ef9f77-321b-4857-88c6-ad88d487aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ee91394-5eac-45b1-a87e-186ab086088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorization - Convert words to numerical feature vectors\n",
    "# vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "\n",
    "# Using hashing instead of CountVectorizer\n",
    "vectorizer = HashingTF(inputCol=\"filtered_words\", outputCol=\"features\", numFeatures=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48f3a4d9-d942-4e32-87c7-9674908d6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(featuresCol=\"features\", labelCol=\"label_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b065270c-4709-408b-b50a-bb8d064e4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Pipeline - setup stages one by one\n",
    "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopwords_remover, vectorizer, logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd07ebbb-7d99-4ac3-9d92-8f2456cf4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "# we train on 80% of data and testing on 20% of data\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3e4f2-1976-43ad-9b7a-afe83cdd44b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/25 14:22:48 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/10/25 14:22:48 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 117:=====>                                                 (1 + 10) / 11]\r"
     ]
    }
   ],
   "source": [
    "# Train the model  - execute pipeline\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d603b-03fc-465d-8889-d955b4185c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
